[2026-02-07T15:34:07.954+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecommerce_etl.silver_orders scheduled__2026-02-06T00:00:00+00:00 [queued]>
[2026-02-07T15:34:07.957+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecommerce_etl.silver_orders scheduled__2026-02-06T00:00:00+00:00 [queued]>
[2026-02-07T15:34:07.958+0000] {taskinstance.py:2170} INFO - Starting attempt 4 of 4
[2026-02-07T15:34:07.963+0000] {taskinstance.py:2191} INFO - Executing <Task(BigQueryInsertJobOperator): silver_orders> on 2026-02-06 00:00:00+00:00
[2026-02-07T15:34:07.967+0000] {standard_task_runner.py:60} INFO - Started process 4110 to run task
[2026-02-07T15:34:07.969+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ecommerce_etl', 'silver_orders', 'scheduled__2026-02-06T00:00:00+00:00', '--job-id', '134', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpdmgvwnr2']
[2026-02-07T15:34:07.970+0000] {standard_task_runner.py:88} INFO - Job 134: Subtask silver_orders
[2026-02-07T15:34:07.992+0000] {task_command.py:423} INFO - Running <TaskInstance: ecommerce_etl.silver_orders scheduled__2026-02-06T00:00:00+00:00 [running]> on host 1d9eed85a9d4
[2026-02-07T15:34:08.028+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ecommerce_etl' AIRFLOW_CTX_TASK_ID='silver_orders' AIRFLOW_CTX_EXECUTION_DATE='2026-02-06T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='4' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2026-02-06T00:00:00+00:00'
[2026-02-07T15:34:08.032+0000] {connection.py:234} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-02-07T15:34:08.032+0000] {base.py:83} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-02-07T15:34:08.032+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-02-07T15:34:08.075+0000] {bigquery.py:2807} INFO - Executing: {'query': {'query': "WITH DeduplicatedOrders AS (\n SELECT\n   *,\n   ROW_NUMBER() OVER(PARTITION BY order_id, created_at ORDER BY created_at) as rn -- Assuming order_id and created_at uniquely identify an order\n FROM\n   `bronze.ext_orders`\n),\nValidatedAndCleanedOrders AS (\n SELECT\n   -- Explicit Data Type Casting and Null Handling\n   order_id, -- Already INT64, included for completeness\n   COALESCE(SAFE_CAST(user_id AS INT64), 0) AS user_id, -- Casts to INT64, replaces NULLs with 0\n   COALESCE(status, 'UNKNOWN') AS status_cleaned, -- Replaces NULL status with 'UNKNOWN'\n   COALESCE(gender, 'UNKNOWN') AS gender_cleaned, -- Replaces NULL gender with 'UNKNOWN'\n   created_at, -- Already TIMESTAMP\n   returned_at, -- Can be NULL, no specific replacement needed unless specified\n   shipped_at, -- Can be NULL, no specific replacement needed unless specified\n   delivered_at, -- Can be NULL, no specific replacement needed unless specified\n   COALESCE(SAFE_CAST(num_of_item AS INT64), 0) AS num_of_item, -- Casts to INT64, replaces NULLs with 0\n\n\n   -- Basic Validation Checks\n   CASE WHEN order_id IS NULL OR order_id <= 0 THEN FALSE ELSE TRUE END AS is_valid_order_id,\n   CASE WHEN COALESCE(SAFE_CAST(user_id AS INT64), 0) IS NULL OR COALESCE(SAFE_CAST(user_id AS INT64), 0) <= 0 THEN FALSE ELSE TRUE END AS is_valid_user_id,\n   CASE WHEN created_at IS NULL OR created_at > CURRENT_TIMESTAMP() THEN FALSE ELSE TRUE END AS is_valid_created_at,\n   CASE\n     WHEN status IN ('Pending', 'Processing', 'Shipped', 'Delivered', 'Cancelled', 'Returned') THEN TRUE\n     ELSE FALSE\n   END AS is_known_status,\n   CASE\n     WHEN gender IN ('M', 'F', 'Other') THEN TRUE\n     ELSE FALSE\n   END AS is_known_gender,\n   CASE WHEN COALESCE(SAFE_CAST(num_of_item AS INT64), 0) < 0 THEN FALSE ELSE TRUE END AS is_valid_num_of_item,\n   -- Temporal consistency checks\n   CASE WHEN shipped_at IS NOT NULL AND shipped_at < created_at THEN FALSE ELSE TRUE END AS is_valid_shipped_time,\n   CASE WHEN delivered_at IS NOT NULL AND shipped_at IS NOT NULL AND delivered_at < shipped_at THEN FALSE ELSE TRUE END AS is_valid_delivered_time,\n   CASE WHEN returned_at IS NOT NULL AND delivered_at IS NOT NULL AND returned_at < delivered_at THEN FALSE ELSE TRUE END AS is_valid_returned_time\n\n\n FROM\n   DeduplicatedOrders\n WHERE rn = 1 -- Keep only the first occurrence for deduplication\n   AND order_id IS NOT NULL -- Exclude rows with a null 'order_id' as it's a critical identifier\n)\nSELECT\n order_id,\n user_id,\n status_cleaned AS status, -- Use the cleaned status\n gender_cleaned AS gender, -- Use the cleaned gender\n created_at,\n returned_at,\n shipped_at,\n delivered_at,\n num_of_item,\n is_valid_order_id,\n is_valid_user_id,\n is_valid_created_at,\n is_known_status,\n is_known_gender,\n is_valid_num_of_item,\n is_valid_shipped_time,\n is_valid_delivered_time,\n is_valid_returned_time\nFROM\n ValidatedAndCleanedOrders\nWHERE\n is_valid_order_id = TRUE\n AND is_valid_user_id = TRUE\n AND is_valid_created_at = TRUE\n AND is_known_status = TRUE\n AND is_known_gender = TRUE\n AND is_valid_num_of_item = TRUE\n AND is_valid_shipped_time = TRUE\n AND is_valid_delivered_time = TRUE\n AND is_valid_returned_time = TRUE; -- Filter to only include rows passing all basic validation", 'useLegacySql': False, 'destinationTable': {'projectId': 'prism-486509', 'datasetId': 'silver', 'tableId': 'orders'}, 'writeDisposition': 'WRITE_TRUNCATE'}}'
[2026-02-07T15:34:08.078+0000] {bigquery.py:1596} INFO - Inserting job ***_ecommerce_etl_silver_orders_2026_02_06T00_00_00_00_00_7bb8fb5361ece771056526dbf0f8bfab
[2026-02-07T15:34:09.139+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 2864, in execute
    job.result(timeout=self.result_timeout, retry=self.result_retry)
  File "/home/airflow/.local/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1595, in result
    do_get_result()
  File "/home/airflow/.local/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1584, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/airflow/.local/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 971, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 261, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 No matching signature for function COALESCE
  Argument types: BOOL, STRING
  Signature: COALESCE([T1, ...])
    Unable to find common supertype for templated argument <T1>
      Input types for <T1>: {BOOL, STRING} at [14:4]; reason: invalidQuery, location: query, message: No matching signature for function COALESCE
  Argument types: BOOL, STRING
  Signature: COALESCE([T1, ...])
    Unable to find common supertype for templated argument <T1>
      Input types for <T1>: {BOOL, STRING} at [14:4]

Location: europe-west1
Job ID: airflow_ecommerce_etl_silver_orders_2026_02_06T00_00_00_00_00_7bb8fb5361ece771056526dbf0f8bfab

[2026-02-07T15:34:09.150+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=ecommerce_etl, task_id=silver_orders, execution_date=20260206T000000, start_date=20260207T153407, end_date=20260207T153409
[2026-02-07T15:34:09.162+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 134 for task silver_orders (400 No matching signature for function COALESCE
  Argument types: BOOL, STRING
  Signature: COALESCE([T1, ...])
    Unable to find common supertype for templated argument <T1>
      Input types for <T1>: {BOOL, STRING} at [14:4]; reason: invalidQuery, location: query, message: No matching signature for function COALESCE
  Argument types: BOOL, STRING
  Signature: COALESCE([T1, ...])
    Unable to find common supertype for templated argument <T1>
      Input types for <T1>: {BOOL, STRING} at [14:4]

Location: europe-west1
Job ID: airflow_ecommerce_etl_silver_orders_2026_02_06T00_00_00_00_00_7bb8fb5361ece771056526dbf0f8bfab
; 4110)
[2026-02-07T15:34:09.174+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2026-02-07T15:34:09.190+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
